{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DlHW0Ve36Xs2"
      },
      "source": [
        "# WIDER Datset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r6NIcisK8fPG"
      },
      "source": [
        "## Downloading and unzipping"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "czACiZcq6KtG",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "!gdown https://drive.google.com/u/0/uc?id=0B6eKvaijfFUDQUUwd21EckhUbWs&export=download\n",
        "!gdown https://drive.google.com/u/0/uc?id=0B6eKvaijfFUDd3dIRmpvSk8tLUk&export=download"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0uGQLEZsrm2Q",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "!wget http://mmlab.ie.cuhk.edu.hk/projects/WIDERFace/support/bbx_annotation/wider_face_split.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JrErR7kaedvY",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "!cp /content/drive/MyDrive/WIDER_Dataset/* /content/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mwlJ80EA7IGl",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "!unzip -qx /content/WIDER_train.zip\n",
        "!unzip -qx /content/WIDER_val.zip\n",
        "!unzip -qx /content/wider_face_split.zip"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KM5Gv9DN8jHa"
      },
      "source": [
        "## Creating the dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0S6T4Il57Puk",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from glob import glob as g\n",
        "import cv2\n",
        "from tqdm.notebook import tqdm\n",
        "from shutil import copy, move\n",
        "from google.colab.files import download"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NRtOjYyJgb0J",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "# Val Dataset\n",
        "new_imgs_dir = '/content/newDataset/images/val'\n",
        "new_lbls_dir = '/content/newDataset/labels/val'\n",
        "label_text_name = '/content/wider_face_split/wider_face_val_bbx_gt.txt'\n",
        "imgs_address = '/content/WIDER_val/images'\n",
        "\n",
        "os.makedirs(new_imgs_dir,exist_ok = True)\n",
        "os.makedirs(new_lbls_dir,exist_ok = True)\n",
        "annots = open(label_text_name) \n",
        "lines = annots.readlines()\n",
        "names =   [x for x in lines if 'jpg' in x]\n",
        "indices = [lines.index(x) for x in names]\n",
        "\n",
        "\n",
        "for n in tqdm(range(len(names[:]))):\n",
        "    i = indices[n]\n",
        "    name = lines[i].rstrip()\n",
        "    old_img_path = os.path.join(imgs_address , name)\n",
        "    name = name.split('/')[-1]\n",
        "    label_path = os.path.join(new_lbls_dir , name.split('.')[0] + '.txt')\n",
        "    img_path = os.path.join(new_imgs_dir , name)\n",
        "    \n",
        "    num_objs = int(lines[i+1].rstrip())\n",
        "    bboxs = lines[i+2 : i+2+num_objs]\n",
        "    bboxs = list(map(lambda x:x.rstrip() , bboxs))\n",
        "    bboxs = list(map(lambda x:x.split()[:4], bboxs))\n",
        "    # if len(bboxs) > 5:\n",
        "    #     continue\n",
        "    img = cv2.imread(old_img_path)\n",
        "    img_h,img_w,_ = img.shape\n",
        "    img_h,img_w,_ = img.shape\n",
        "    f = open(label_path, 'w')\n",
        "    count = 0 # Num of bounding box\n",
        "    for bbx in bboxs:\n",
        "        x1 = int(bbx[0])\n",
        "        y1 = int(bbx[1])\n",
        "        w = int(bbx[2])\n",
        "        h = int(bbx[3])\n",
        "    #     #yolo:\n",
        "        x = (x1 + w//2) / img_w\n",
        "        y = (y1 + h//2) / img_h\n",
        "        w = w / img_w\n",
        "        h = h / img_h\n",
        "        if w * h * 100 > 2:\n",
        "            yolo_line = f'{0} {x} {y} {w} {h}\\n'\n",
        "            f.write(yolo_line)\n",
        "            count += 1\n",
        "    f.close()\n",
        "    if count > 0:   \n",
        "        copy(old_img_path , img_path)\n",
        "    else:\n",
        "        os.remove(label_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fdzXpR44gsHT",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "# Train Dataset\n",
        "new_imgs_dir = '/content/newDataset/images/train'\n",
        "new_lbls_dir = '/content/newDataset/labels/train'\n",
        "label_text_name = '/content/wider_face_split/wider_face_train_bbx_gt.txt'\n",
        "imgs_address = '/content/WIDER_train/images'\n",
        "\n",
        "os.makedirs(new_imgs_dir,exist_ok = True)\n",
        "os.makedirs(new_lbls_dir,exist_ok = True)\n",
        "annots = open(label_text_name) \n",
        "lines = annots.readlines()\n",
        "names =   [x for x in lines if 'jpg' in x]\n",
        "indices = [lines.index(x) for x in names]\n",
        "\n",
        "\n",
        "for n in tqdm(range(len(names[:]))):\n",
        "    i = indices[n]\n",
        "    name = lines[i].rstrip()\n",
        "    old_img_path = os.path.join(imgs_address , name)\n",
        "    name = name.split('/')[-1]\n",
        "    label_path = os.path.join(new_lbls_dir , name.split('.')[0] + '.txt')\n",
        "    img_path = os.path.join(new_imgs_dir , name)\n",
        "    num_objs = int(lines[i+1].rstrip())\n",
        "    bboxs = lines[i+2 : i+2+num_objs]\n",
        "    bboxs = list(map(lambda x:x.rstrip() , bboxs))\n",
        "    bboxs = list(map(lambda x:x.split()[:4], bboxs))\n",
        "    # if len(bboxs) > 5:\n",
        "    #     continue\n",
        "    img = cv2.imread(old_img_path)\n",
        "    img_h, img_w, _ = img.shape\n",
        "    f = open(label_path, 'w')\n",
        "    count = 0 # Num of bounding box\n",
        "    for bbx in bboxs:\n",
        "        x1 = int(bbx[0])\n",
        "        y1 = int(bbx[1])\n",
        "        w = int(bbx[2])\n",
        "        h = int(bbx[3])\n",
        "    #     #yolo:\n",
        "        x = (x1 + w//2) / img_w\n",
        "        y = (y1 + h//2) / img_h\n",
        "        w = w / img_w\n",
        "        h = h / img_h\n",
        "        if w * h * 100 > 2:\n",
        "            yolo_line = f'{0} {x} {y} {w} {h}\\n'\n",
        "            f.write(yolo_line)\n",
        "            count += 1\n",
        "    f.close()\n",
        "    if count > 0:   \n",
        "        copy(old_img_path , img_path)\n",
        "    else:\n",
        "        os.remove(label_path)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ztFWy1RgEL__"
      },
      "source": [
        "## Resizing and Showing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6VRAaXni-fnU",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "def resize_img(input_name , output_name, target_width = 640):\n",
        "    im = cv2.imread(input_name)\n",
        "    h,w,_  = im.shape\n",
        "    target_height = int(h / w * target_width)\n",
        "    im = cv2.resize(im , (target_width , target_height), interpolation = cv2.INTER_AREA)\n",
        "    cv2.imwrite(output_name , im)\n",
        "\n",
        "def resize_all_imgs(imgs_dir):\n",
        "    names = g(os.path.join(imgs_dir , '*'))\n",
        "    for img in tqdm(names):\n",
        "        resize_img(img, img)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MkN_JljFHES4",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "names = g('/content/newDataset/labels/*/*')\n",
        "print(f'Threre are {len(names)}  images')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O4TPgkVM_JUY",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "resize_all_imgs('/content/newDataset/images/*')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-LRleqJWnPEt",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "n = np.random.randint(0, len(names))\n",
        "f = open(names[n])\n",
        "\n",
        "lines = f.readlines()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KSY97_n9neJA",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "lines"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hkB5jM5AD9aR",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "n = np.random.randint(0, len(names))\n",
        "f = open(names[n])\n",
        "\n",
        "lines = f.readlines()\n",
        "classes = list(map(lambda x: int(x[0]), lines))\n",
        "lines = list(map(lambda x:x.rstrip()[2:], lines))\n",
        "objects = list(map(lambda x:(x.split()), lines))\n",
        "\n",
        "img = cv2.imread(names[n].replace('txt','jpg').replace('labels', 'images'))\n",
        "for c, bbox in zip(classes, objects):\n",
        "  bbox = list(map(lambda x:float(x), bbox))\n",
        "  x,y,w,h = bbox\n",
        "  img_h = img.shape[0]\n",
        "  img_w = img.shape[1]\n",
        "  x = int(x * img_w)\n",
        "  w = int(w * img_w)\n",
        "  y = int(y * img_h)\n",
        "  h = int(h * img_h)\n",
        "  color = (255,100,50)\n",
        "  cv2.rectangle(img , (int(x-w/2), int(y-h/2)), (int(x+w/2), int(y+h/2)), color , 4)\n",
        "plt.figure(figsize = (8,8))\n",
        "plt.imshow(img[:,:,::-1]); plt.axis('off')\n",
        "print(f'number of bounding boxes : {len(classes)}')\n",
        "print(f'Shape on the image : {img.shape}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hi56RN188VwK"
      },
      "source": [
        "## Create Grid"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JtSqysopO22U",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from mpl_toolkits.axes_grid1 import ImageGrid\n",
        "import numpy as np\n",
        "\n",
        "images = []\n",
        "for _ in range(25):\n",
        "    n = np.random.randint(0, len(names))\n",
        "    f = open(names[n])\n",
        "\n",
        "    lines = f.readlines()\n",
        "    classes = list(map(lambda x: int(x[0]), lines))\n",
        "    lines = list(map(lambda x:x.rstrip()[2:], lines))\n",
        "    objects = list(map(lambda x:(x.split()), lines))\n",
        "\n",
        "    img = cv2.imread(names[n].replace('txt','jpg').replace('labels', 'images'))\n",
        "    for c, bbox in zip(classes, objects):\n",
        "        bbox = list(map(lambda x:float(x), bbox))\n",
        "        x,y,w,h = bbox\n",
        "        img_h = img.shape[0]\n",
        "        img_w = img.shape[1]\n",
        "        x = int(x * img_w)\n",
        "        w = int(w * img_w)\n",
        "        y = int(y * img_h)\n",
        "        h = int(h * img_h)\n",
        "        color = (255,100,50)\n",
        "        cv2.rectangle(img , (int(x-w/2), int(y-h/2)), (int(x+w/2), int(y+h/2)), color , 6)\n",
        "    # plt.figure(figsize = (8,8))\n",
        "    # plt.imshow(img[:,:,::-1]); plt.axis('off')\n",
        "    # print(f'number of bounding boxes : {len(classes)}')\n",
        "    images.append(img[:,:,::-1])\n",
        "fig = plt.figure(figsize=(16., 16.))\n",
        "grid = ImageGrid(fig, 111,  # similar to subplot(111)\n",
        "                 nrows_ncols=(5 ,5),  # creates 2x2 grid of axes\n",
        "                 axes_pad=0.1,  # pad between axes in inch.\n",
        "                 )\n",
        "\n",
        "for ax, im in zip(grid, images):\n",
        "    # Iterating over the grid returns the Axes.\n",
        "    ax.imshow(im)\n",
        "    ax.axis('off')\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xL0H7RuzPbOE",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "fig.savefig('grid_output.png')\n",
        "download('grid_output.png')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rbIA3TEVP7gq",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O4ffw18K8bu0"
      },
      "source": [
        "## Train/Val >>>> ZIP"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qzzzCx0JAgUz",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "os.makedirs('/content/Yolo/images', exist_ok= True)\n",
        "os.makedirs('/content/Yolo/labels', exist_ok= True)\n",
        "os.makedirs('/content/Yolo/images/train', exist_ok= True)\n",
        "os.makedirs('/content/Yolo/images/val', exist_ok= True)\n",
        "os.makedirs('/content/Yolo/labels/train', exist_ok= True)\n",
        "os.makedirs('/content/Yolo/labels/val', exist_ok= True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y4CKO4g-AnmT",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "labels_address = '/content/newDataset/labels/'\n",
        "imgs_address = '/content/newDataset/images/'\n",
        "np.random.seed(101)\n",
        "names = os.listdir(imgs_address)\n",
        "randvec = np.random.rand(len(names))\n",
        "i = 0\n",
        "for name in tqdm(names[:]):\n",
        "\n",
        "  epsilon = randvec[i]\n",
        "  i += 1\n",
        "  epsilon = np.random.rand(1)\n",
        "  if epsilon>0.85: #Validation\n",
        "    copy(imgs_address + name , '/content/Yolo/images/val/' + name)\n",
        "    copy(labels_address + name.split('.')[0] + '.txt' , '/content/Yolo/labels/val/' + name.split('.')[0] + '.txt')\n",
        "    \n",
        "  \n",
        "  else: #Train\n",
        "    copy(imgs_address + name,  '/content/Yolo/images/train/' + name)\n",
        "    copy(labels_address + name.split('.')[0] + '.txt' , '/content/Yolo/labels/train/' + name.split('.')[0] + '.txt')\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V_0pl_5RBhmw",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "!zip -rq Yolo.zip /content/Yolo"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LZbrBi3TAai5"
      },
      "source": [
        "# Training Yolo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zU8bIyuX8cwP",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from IPython.display import clear_output\n",
        "torch.cuda.get_device_name()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SON9CNd1AZk7",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "!git clone https://github.com/ultralytics/yolov5.git\n",
        "!pip install -qr /content/yolov5/requirements.txt\n",
        "%cd yolov5\n",
        "clear_output()  \n",
        "f = open('/content/yolov5/data/dataset.yaml', 'w')\n",
        "f.write('train: /content/newDataset/images/train')\n",
        "f.write('\\nval: /content/newDataset/images/val')\n",
        "f.write('\\nnc: {}'.format(1))\n",
        "f.write(\"\\nnames: ['Face']\")\n",
        "\n",
        "f.close()\n",
        "\n",
        "# f = open('/content/yolov5/models/newyolov5s.yaml', 'w')\n",
        "# f.write('nc: {}\\n'.format(1))\n",
        "# f.write('\\n'.join(open('/content/yolov5/models/yolov5s.yaml').read().split('\\n')[2:]))\n",
        "# f.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d7kvQIS4DG2I",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "!python train.py --img 640 --batch 64 --workers 8 --epochs 300\\\n",
        "  --weights yolov5s.pt\\\n",
        "  --cfg /content/yolov5/models/yolov5s.yaml\\\n",
        "  --data /content/yolov5/data/dataset.yaml\\\n",
        "  --weights yolov5s\\"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "r6NIcisK8fPG",
        "ztFWy1RgEL__",
        "hi56RN188VwK",
        "O4ffw18K8bu0",
        "LZbrBi3TAai5"
      ],
      "name": "Face Detection.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
